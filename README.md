# hui--
诗词数据采集与处理
本项目围绕唐诗数据，涵盖了数据采集、数据清洗、统计分析、文本特征工程和可视化等完整流程。通过自动化脚本从古诗文网爬取诗歌数据，利用Python进行数据统计、分词、TF-IDF特征提取，并生成词云和统计报表，助力后续文本挖掘与分析。
主要工作与技术亮点：
使用 requests、BeautifulSoup 和 lxml 自动化爬取古诗文网唐诗数据，结构化存储诗歌类型、题目、作者及内容。
利用 jieba 进行中文分词，结合 pandas 实现诗歌类型和作者数量的统计分析，并导出为Excel报表。
应用 matplotlib 和 wordcloud 生成基于诗歌内容的词云图，实现文本可视化。
采用 scikit-learn 的 TfidfVectorizer 对诗歌内容进行TF-IDF特征向量化，为后续机器学习和文本挖掘打下基础。
熟练处理文本编码、数据清洗与特征工程等实际问题。
